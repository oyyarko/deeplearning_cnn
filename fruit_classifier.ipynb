{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fruit-classifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1jepCrawiuRWl6efWg-nxRFgTeTOHHPWq",
      "authorship_tag": "ABX9TyNwi8mDOLLTbtFb9G/upBcF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyyarko/deeplearning_cnn/blob/master/fruit_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb8hLOLv6X-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Deep Learning/Fruit Classifier')\n",
        "#!curl 'https://storage.googleapis.com/kaggle-data-sets/5857/1107198/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1589009705&Signature=VRpcG5rNwNOn2BKIzU%2FtNRjREaVk0jo3j%2FVCixqHnkieBCcsqeKaxiNoIkuhdK3TyyQYoaTrs6tIjyznmFNoy1fVpME2kOehUFunZHc7CZsZEbx2LdjJMTz32Z6Txko6Bn7dA3zrxHGMtor7YUOyIYlNSlVxhXd6wWGG07O%2BdyGjXEUYiLYWEbYJBh5Drtpo0%2BmnSC3D1%2Fylj%2FcPMHH5GKOP3%2FFbuAvEQ2KOrPchzjV4n9fWJS2Se1Zk5M0mZDGe9Zuri%2Bt0wvKjmjk%2F%2BTvUY0k4vL3tLq39IffZcjsEZGzjy%2BKHY7xdB%2Fc2jjGjrf7t786REjbtrRjnGALayPR4Qw%3D%3D&response-content-disposition=attachment%3B+filename%3Dfruits.zip' -H 'User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:75.0) Gecko/20100101 Firefox/75.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -o data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-BnApyPVM1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndcw6rqJ66z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owGR5rtF9puS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#train_data_dir = sys.path.append('/fruit-360/Training')\n",
        "#test_data_dir = sys.path.append('/fruit-360/Test')\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/Deep Learning/Fruit Classifier/fruits-360/Training'\n",
        "validation_data_dir = '/content/drive/My Drive/Deep Learning/Fruit Classifier/fruits-360/Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcQaWDT-ygs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKT_H9CL_WuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "#CCMD\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(img_rows, img_cols, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5tzR8TlCuwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRLfx-YxC8TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = RMSprop(learning_rate=0.001)\n",
        "epochs = 10\n",
        "\n",
        "checkpoint = ModelCheckpoint('fruit_classifier.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min')\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', \n",
        "                          min_delta=0, \n",
        "                          patience=3, \n",
        "                          verbose=1, \n",
        "                          mode='min', \n",
        "                          restore_best_weights=True)\n",
        "\n",
        "reducelr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                             factor=0.2, \n",
        "                             patience=3, \n",
        "                             verbose=1, \n",
        "                             mode='min', \n",
        "                             min_delta=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SEOLpBAD7DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [checkpoint, earlystop, reducelr]\n",
        "nb_train_samples = 60486\n",
        "nb_test_samples = 20618\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = nb_train_samples//batch_size,\n",
        "                              epochs=epochs,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=nb_test_samples//batch_size,\n",
        "                              shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPU-wj9Erzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "Y_pred = model.predict_generator(validation_generator, nb_test_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHMSQLymgIeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_labels.items()}\n",
        "\n",
        "print('Classification Report:')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oF5tiD4gtuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
        "plt.imshow(cnf_matrix, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_marks, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_marks, target_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgGueul0l1mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --NotebookApp.port_retries=0 --notebook-dir=\"\" --no-browser --allow-root --NotebookApp.token='' --NotebookApp.disable_check_xsrf=True --port=8888"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p0hEsRikhGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import re\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = load_model('fruit_classifier.h5')\n",
        "\n",
        "def draw_test(name, pred, im, true_label):\n",
        "    BLACK = [0,0,0]\n",
        "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 500 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
        "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
        "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
        "    #img = cv2.imread(name, expanded_image)\n",
        "    cv2_imshow(expanded_image)\n",
        "\n",
        "\n",
        "def getRandomImage(path, img_width, img_height):\n",
        "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
        "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
        "    random_directory = np.random.randint(0,len(folders))\n",
        "    path_class = folders[random_directory]\n",
        "    file_path = path + path_class\n",
        "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
        "    random_file_index = np.random.randint(0,len(file_names))\n",
        "    image_name = file_names[random_file_index]\n",
        "    final_path = file_path + \"/\" + image_name\n",
        "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class\n",
        "\n",
        "# dimensions of our images\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "\n",
        "files = []\n",
        "predictions = []\n",
        "true_labels = []\n",
        "# predicting images\n",
        "for i in range(0, 10):\n",
        "    path = '/content/drive/My Drive/Deep Learning/Fruit Classifier/fruits-360/Test/'\n",
        "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
        "    files.append(final_path)\n",
        "    true_labels.append(true_label)\n",
        "    x = image.img_to_array(img)\n",
        "    x = x * 1./255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size = 10)\n",
        "    predictions.append(classes)\n",
        "    \n",
        "for i in range(0, len(files)):\n",
        "    image = cv2.imread((files[i]))\n",
        "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELhCCcfjlEaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}